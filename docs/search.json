[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Readings in Causal Inference, Fall 2023",
    "section": "",
    "text": "During the Fall 2023 I’m doing a reading-based independent study and writing up my notes to share here from some classic and modern texts in causal inference with a particular interest on a few subtopics including 1) complex mediators, 2) the role of semiparametric methods, and 3) doubly-robust learning.\n\n\n\n\n\n\nReading List for the Semester\n\n\n\n\n\n\n\n\nArticle Reference\nLink to Article/Book\n\n\n\n\nRosenbaum, P. R., & Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1), 41-55.\nArticle\n\n\nRobins, J. M., & Ritov, Y. (1997). Toward a curse of dimensionality appropriate (CODA) asymptotic theory for semi-parametric models. Statistics in medicine, 16(3), 285-319.\nArticle\n\n\nRobins, J. M., Hernán, M. Á., & Brumback, B. (2000). Marginal structural models and causal inference in epidemiology. Epidemiology, 11(5), 550-560.\nArticle\n\n\nDawid, A. P. (2000). Causal inference without counterfactuals. Journal of the American Statistical Association, 95(450), 407-424.\nArticle\n\n\nPearl, J. (2001). Direct and indirect effects. Proceedings of the seventeenth conference on uncertainty in artificial intelligence.\nArticle\n\n\nZhang, Z., & Rubin, D. B. (2003). Estimation of causal effects via principal stratification when some outcomes are truncated by ‘death’. Journal of Educational and Behavioral Statistics, 28(4), 353-368.\nArticle\n\n\nRubin, D. B. (2005). Causal inference using potential outcomes: Design, modeling, decisions. Journal of the American Statistical Association, 100(469), 322-331.\nArticle\n\n\nHernán, M. A., & Robins, J. M. (2006). Instruments for causal inference: an epidemiologist’s dream?. Epidemiology, 17(4), 360-372.\nArticle\n\n\nShalizi, C. R., & Thomas, A. C. (2010). Homophily and contagion are generically confounded in observational social network studies. Sociological methods & research, 40(2), 211-239.\nArticle\n\n\nVan der Laan, M. J., & Rose, S. (2011). Targeted Learning: Causal Inference for Observational and Experimental Data. Springer.\nBook\n\n\nPeng, R. D. (2011). Reproducible research in computational science. Science, 334(6060), 1226-1227.\nArticle\n\n\nTchetgen Tchetgen, E. J., & Shpitser, I. (2012). Semiparametric theory for causal mediation analysis: efficiency bounds, multiple robustness and sensitivity analysis. The Annals of Statistics, 40(3), 1816-1845.\nArticle\n\n\nPearl, J. (2012). The causal mediation formula—a guide to the assessment of pathways and mechanisms. Prevention science, 13(4), 426-436.\nArticle\n\n\nTchetgen Tchetgen, E. J. (2013). Identification and estimation of survivor average causal effects. Biometrika, 100(2), 503-518.\nArticle\n\n\nTchetgen Tchetgen, E. J. (2014). The control outcome calibration approach for causal inference with unobserved confounding. The American Statistician, 68(1), 27-32.\nArticle\n\n\nVanderWeele, T. J., & Tchetgen Tchetgen, E. J. (2014). Mediation analysis with time varying exposures and mediators. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 76(3), 523-545.\nArticle\n\n\nVanderWeele, T. J. (2015). Explanation in causal inference: methods for mediation and interaction. Oxford University Press.\nBook\n\n\nImbens, G. W., & Rubin, D. B. (2015). Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.\nBook\n\n\nPeters, J., Janzing, D., & Schölkopf, B. (2017). Elements of causal inference: foundations and learning algorithms. MIT press.\nBook\n\n\nRobins, J. M., Sued, M., Lei, G., & Mínguez, D. (2017). Comment: The self-controlled case series method - An innovative design for home and online randomized controlled trials. Statistical Science, 32(2), 264-267.\nArticle\n\n\nHernán, M. A., & Robins, J. M. (2018). Causal Inference. Chapman & Hall/CRC.\nBook\n\n\nChernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., & Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21(1), C1-C68.\nLink\n\n\n\n\n\n\nSupplemental Articles\nLink to Article\n\n\n\n\nLu Cheng, Ruocheng Guo, and Huan Liu. 2022. Causal Mediation Analysis with Hidden Confounders. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (WSDM ’22). Association for Computing Machinery, New York, NY, USA.\nArticle\n\n\nZhang, Z., Zheng, W., & Albert, J. M. (2019). High-dimensional mediation analysis with latent variables in randomized clinical trials. Statistical Methods in Medical Research, 28(10-11), 3186-3200.\nArticle\n\n\nDerkach A, Pfeiffer RM, Chen TH, Sampson JN. High dimensional mediation analysis with latent variables. Biometrics. 2019 May 5.\nArticle\n\n\nZeng P, Shao Z, Zhou X. Statistical methods for mediation analysis in the era of high-throughput genomics: Current successes and future challenges. Computational and Structural Biotechnology Journal. 2021.\nArticle\n\n\nEric J. Tchetgen Tchetgen. Ilya Shpitser. “Semiparametric theory for causal mediation analysis: Efficiency bounds, multiple robustness and sensitivity analysis.” Ann. Statist. June 2012. https://doi.org/10.1214/12-AOS990\nArticle\n\n\nPeters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). Deep contextualized word representations. arXiv preprint arXiv:1802.05365.\nArticle\n\n\nNima S Hejazi and others, Nonparametric causal mediation analysis for stochastic interventional (in)direct effects, Biostatistics, July 2023. Article\nArticle\n\n\nHernán, M., Taubman, S. Does obesity shorten life? The importance of well-defined interventions to answer causal questions. Int J Obes 32 (Suppl 3), S8–S14 (2008). https://doi.org/10.1038/ijo.2008.82\nArticle\n\n\nPeters, J., Mooij, J. M., Janzing, D., & Schölkopf, B. (2014). Causal discovery with continuous additive noise models.\nArticle\n\n\nMooij, J. M., Peters, J., Janzing, D., Zscheischler, J., & Schölkopf, B. (2016). Distinguishing cause from effect using observational data: methods and benchmarks. The Journal of Machine Learning Research.\nArticle\n\n\n\n\n\n\n\nWeek 1: The Central Role of the Propensity Score in Observational Studies for Causal Effects by Paul R. Rosenbaum and Donald B. Rubin (1983), Biometrika\nHTML  PDF\n\nWeek 2a: Marginal Structural Models for Causal Inference by James M. Robin, Miguel Ángel Hernán, and Babette Brumback (2000), Epidemiology\nHTML  PDF\n\nWeek 2b: Causal Inference Without Counterfactuals  by Alexander Phillip Dawid (2000). JASA\nHTML PDF"
  },
  {
    "objectID": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#introduction",
    "href": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#introduction",
    "title": "3  Marginal Structural Models",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\nThe key problem this paper addresses is the bias induced by time-dependent confounders that are also affected by previous treatment — which are handled by the introduction of marginal structural models that can be consistently estimated using inverse-probability-of-treatment weighted (IPTW) estimators.\nDefinition. Time-dependent confounders are covariates that are a risk factor for, or predictor of, the event of interest and also predicts subsequent exposure.\nWe are particularly interested in time-dependent confounders that are also affected or predicted by past exposure history (Condition 2)."
  },
  {
    "objectID": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#time-dependent-confounding",
    "href": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#time-dependent-confounding",
    "title": "3  Marginal Structural Models",
    "section": "3.2 Time-Dependent Confounding",
    "text": "3.2 Time-Dependent Confounding\n\nConsider a follow-up study of HIV-infected patients. Let \\(A_k\\) be the dose of the treatment or exposure of interest, say zidovudine (AZT) on the \\(k\\)th day since start of follow-up. Let \\(Y\\) be a dichotomous outcome of interest (for example, \\(Y = 1\\) if HIV RNA is not detectable in the blood and 0 otherwise) measured at end of follow-up on day \\(K+1\\). Our goal is to estimate the time-dependent treatment \\(A_k\\) on the outcome \\(Y\\).\n\nLet \\(L_k\\) represent the vector of all measured risk factors on day \\(k\\) for the outcome such as age, CD4 lymphocyte count, white blood count, hematocrit, diagnosis of AIDS, and presence of absence of symptoms and opportunistic infections. Let \\(U_k\\) represent the value(s) on day \\(k\\) of all unmeasured causal risk factors for \\(Y\\).\n\n\n\n\n\nFigure 1a. The most complex of the causal graphs for time-dependent exposure.\n\n\n\n\n\n\n\n\n\nFigure 1b. Similar to the above graph, but missing the arrows from \\(U_{t_1}\\) to \\(A_{t_2}\\) for \\(t_1, t_2 \\in \\{0, 1\\}\\).\n\n\n\n\n\n\n\n\n\nFigure 1c. Again similar to the above graph, but also missing the arrows from \\(L_{t_1}\\) to \\(A_{t_2}\\) for \\(t_1, t_2 \\in \\{0, 1\\}\\).\n\n\n\n\nBefore diving immediately into how to address time-varying confounding that is affected by antecedent exposures, we establish some preliminary findings in the setting of point-treatment studies.\n\n\n\n\n\nFigure 2 |> a. A causal graph for a point-exposure.\n\n\n\n\n\n\n\n\n\nFigure 2b. Similar to above but missing the arrow from \\(U_0 o A_0\\).\n\n\n\n\n\n\n\n\n\nFigure 2c. Again similar to above but missing the arrow from \\(L_0 o A_0\\).\n\n\n\n\n\nI think Robins, Hernán, and Brumback summarize the problem with time-varying confounders quite clearly in section 7.1:\n“… Standard regression methods adjust for covariates by including them in the model as regressors. These standard methods may fail to adjust appropriately for confounding due to measured confounders \\(L_k\\) when treatment is time varying because (1) \\(L_k\\) may be a confounder for later treatment and thus must be adjusted for, but (2) may also be affected by earlier treatment and thus should not be adjusted for by standard methods. A solution to this conundrum is to adjust for the time-dependent covariates \\(L_k\\) by using them to calculate the weights \\(sw_i\\) rather than by adding \\(L_k\\) to the regression model as regressors.”"
  },
  {
    "objectID": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#counterfactuals-in-point-treatment-studies",
    "href": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#counterfactuals-in-point-treatment-studies",
    "title": "3  Marginal Structural Models",
    "section": "3.3 Counterfactuals in Point-Treatment Studies",
    "text": "3.3 Counterfactuals in Point-Treatment Studies\nIn an effort to help orient the readers, the authors provide some basic background on causal inference in point-treatment studies (Figures 2a-2c) to help keep us all grounded before moving on to more complicated settings.\nThrough this section (\\(\\S2\\)) the authors contrast crude measures with causal measures explaining that the causal measures will equal the crude measures when the analysis is unconfounded.\n\\[cRD = Pr[Y = 1 | A_0 = 1] - Pr[Y = 1 | A_0 = 0] \\quad \\text{\\small (Crude Risk Difference)}\\] \\[cRR = Pr[Y = 1 | A_0 = 1]/Pr[Y = 1 | A_0 = 0] \\quad \\text{\\small (Crude Risk Ratio)}\\] \\[cOR = \\frac{Pr[Y = 1 | A_0 = 1]/Pr[Y=1 | A_0 = 0]}{Pr[Y=0 | A_0 = 1]/Pr[Y=0 | A_0 = 0]} \\quad \\text{\\small (Crude Odds Ratio)}\\]\n\\[Pr[Y_{a_0 = 1} = 1] - Pr[Y_{a_0 = 0} = 1] \\quad \\text{\\small (Causal Risk Difference)}\\] \\[Pr[Y_{a_0 = 1} = 1]/Pr[Y_{a_0 = 0} = 1] \\quad \\text{\\small (Causal Risk Ratio)}\\] \\[\\frac{Pr[Y_{a_0 = 1} = 1]/Pr[Y_{a_0 = 0} = 1]}{Pr[Y_{a_0=1}=0]/Pr[Y_{a_0=0} = 0]} \\quad \\text{\\small (Causal Risk Ratio)}\\]\nNote that the way I’ve written the odds ratios is to make the structure of them obvious as ratios of odds, but of course one can re-express any fraction written \\(\\displaystyle \\frac{a / b}{c / d} = \\frac{a d}{b c}\\), which is how they’re presented in the paper.\nAn important point they make is that because of the possibility of effect modification, the population causal parameter need not be the same as its estimate in a particular stratum of measured risk factors even if the treatment is unconfounded.\nTo estimate these quantities of interest, we might fit linear, exponential, and logistic models depending on expert knowledge about the nature of the data being considered (and what type of exposure-response curve we expect):\n\\[Pr[Y_{a_0} = 1] = \\phi_0 + \\phi_1 a_0\\] \\[\\log Pr[Y_{a_0} = 1] = \\theta_0 + \\theta_1 a_0\\] \\[\\text{logit} Pr[Y_{a_0} = 1] = \\beta_0 + \\beta_1 a_0\\]\nInterpreting, the causal RD is \\(\\phi_1\\), the causal RR is \\(e^{\\theta_1}\\), and the causal OR is \\(e^{\\beta_1}\\).\nThese models are described as marginal because they model the marginal distribution of the counterfactual random variables \\(Y_{a_0=1}\\) and \\(Y_{a_0=1}\\) rather than the joint distribution (as in, they do not model \\(\\text{cor}(Y_{a_0=1}, Y_{a_0=0})\\)). They are said to be structural because they model the probabilities of counterfactual variables (apparently models for counterfactual variables are often called structural in the econometrics and social science literature).\nI’m a little confused about their claim that these are saturated models: they say that they’re saturated because each model has two unknown parameters and places no restriction on the probabilities for \\(Y_{a_0 = 1}\\) and \\(Y_{a_0 = 0}\\). I guess I’m just used to a different definition of saturated in which saturation refers to the model having as many parameters as it has data points, which does not feel like it’s necessarily true here."
  },
  {
    "objectID": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#no-unmeasured-confounders",
    "href": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#no-unmeasured-confounders",
    "title": "3  Marginal Structural Models",
    "section": "3.4 No Unmeasured Confounders",
    "text": "3.4 No Unmeasured Confounders\nNext a claim is introduced: if we weight the observations by \\(w_i = 1/Pr[A_0 = a_{0i} | L_0 = l_{0i}]\\) where \\(l_{0i}\\) and \\(a_{0i}\\) are the measured covariates and exposures for subject \\(i\\), then we should recover unbiased estimates of the causal quantities of interest.\nA rough sketch of why this should work is presented that rests on two additional claims:\n\nIn the constructed pseudopopulation, \\(A_0\\) should be unconfounded by the measured covariates \\(L_0\\).\n\\(Pr(Y_{a_0=1} = 1)\\) and \\(Pr(Y_{a_0=1} = 0)\\) are the same as in the true study population so that the causal RD, RR, and OR are the same in both populations.\n\nProof of 1. We want to show that \\[Pr^W(A = a | L = l) \\stackrel{claim}{=} Pr^W(A = a),\\] where \\(Pr^W\\) refers to probability in the reweighted pseudopopulation.\nI will only show this for the case where both \\(A\\) and \\(L\\) are dichotomous.\nFirst, we can establish that \\[Pr^W(A = a | L = l) = \\frac{N_{(A = a, L =l)} w}{\\sum_{i \\colon L_i = l} w_i},\\] where \\(w = 1/Pr(A = a|L=l)\\) is a scalar-value and\n\\[w_i = \\left\\{ \\begin{array}{ll} 1/Pr(A=1|L=l) & \\text{ if } A_i = 1 \\\\\n1/Pr(A=0|L=l) & \\text{ if } A_i = 0 \\end{array}\\right.\\]\nwhere \\(N_{(A=a,L=l)} \\stackrel{\\text{def}}{=} \\sum_{i \\colon a_i = a, l_i = l} 1\\).\nLetting \\(w' = 1/Pr(A = 1-a | L=l)\\), then we have that:\n\\[Pr^W(A = a | L = l) = \\frac{N_{(A=a, L=l)}w}{N_{(A=a,L=l)}w + N_{(A=1-a,L=l)}w'}.\\]\nSubstituting that \\(Pr(A = a | L = l)\\) is estimated by \\(N_{(A=a,L=l)}/N_{(L=l)}\\), we have that\n\n\\[Pr^W(A = a | L = l) = \\frac{\\cancel{N_{(A=a, L=l)}} \\frac{N_{(L=l)}}{\\cancel{N_{(A=a,L=l)}}}}{\n\\cancel{N_{(A=a,L=l)}} \\frac{N_{(L=l)}}{\\cancel{N_{(A=a,L=l)}}} + \\cancel{N_{(A=1-a,L=l)}} \\frac{N_{(L=l)}}{\\cancel{N_{(A=1-a,L=l)}}}}\\] \\[ = \\frac{N_{(L=l)}}{2 N_{(L=l)}}\\] \\[ = \\frac{1}{2}\\]\nIn general, if \\(L\\) took on more than just two values, we find that the probability that \\(A=a\\) is the inverse of the number of levels of \\(L\\), which is independent of any single value that \\(L\\) could take on.\n\n\\(\\square\\)\n\nIf we consider the 3-way tables necessary in the situation when \\(A\\), \\(L\\), and \\(Y\\) are each dichotomous, we’re looking at something like this (for a simulated study of 1,000 participants):\n\n\n\n\n\n\n\n\n\nAfter applying inverse probability of treatment weights:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter some searching, I believe I have found a proof, in Rebecca Barter’s blog-post on The intuition behind inverse probability weighting in causal inference.\nBefore getting into the proof, she helpfully reminds us that a causal estimand is identifiable when (1) exchangeability/ignorability, (2) consistency, and (3) positivity all hold.\nDefinition. Exchangeability is the assumption we can re-arrange our observations without altering our conclusions. In the context of causal inference, we’re saying that we’d like our observations to be identically and independently distributed, same for the treatment assignment mechanism, and that therefore except for the treatment individual units received, we can permute them without changing our results.\nDefinition. Consistency refers to whether or not our model of potential (unobserved) outcomes is valid, in that our model is consistent with the reality of the data generating processes if we are making accurate statements regarding \\(Pr(\\text{outcomes}|\\text{exposures}).\\)\nDefinition. Positivity refers to the fact that all observations necessarily must have strictly positive probability of being assigned to either the treatment or control group — because otherwise if there is 0 probability of assignment to one of the treatment or control groups, we will necessarily lack observations from that group and thus unable to form causal estimates.\nIf we were to have exchangeability, consistency, and positivity, then we could say that the average treatment effect is estimated by \\[\\frac{\\sum_{i \\colon A=1} Y_i}{N_{(A=1)}} - \\frac{\\sum_{i \\colon A = 0} Y_i}{N_{(A=0)}},\\] since by exchangeability the observations are not confounded.\nNow we can proceed to proving the claim that re-weighting the population as described produces a pseudopopulation in which the causal estimate is unbiased.\nProof. Let \\(p(l) = Pr(A=1|L=l)\\) where for treated individuals we will weight them by \\(1/p(l)\\) and for untreated individuals we will weight them by \\(1/(1-p(l))\\) and we would estimate \\(\\hat p\\) by a logistic regression model.\nThe causal estimate with inverse probability of treatment weighting is then given by:\n\\[\\sum_{i \\colon A=1} \\frac{Y_i}{N_{(A=1)} \\hat p(L_i)} - \\sum_{i \\colon A = 0}\n\\frac{Y_i}{N_{(A=0)} (1-\\hat p(L_i))}\\]\n\\[ = \\sum_{i}^n \\frac{Y_iA_i}{n \\hat p(L_i)} - \\sum_{i}^n\n\\frac{Y_i(1-A_i)}{n (1-\\hat p(L_i))},\\]\nwhere \\(n\\) is the total population size of observations and \\(N_(...)\\) is my short-hand notation for \\(\\displaystyle \\sum_{i \\colon ...} 1\\).\nWhat remains to be checked is if the above is equal to \\(\\mathbb E[Y_{A=1}] - \\mathbb E[Y_{A=0}]\\) (with respect to the super-population that we assume is exchangeable/unconfounded).\nWe will do so by verifying that \\(\\mathbb E\\left[ \\frac{YA}{p(L)} \\right] = \\mathbb E[Y_{A=1}]\\) (and the same steps would follow for showing \\(\\mathbb E\\left[ \\frac{Y(1-A)}{1-p(L)} \\right] = \\mathbb E[Y_{A=0}]\\).\n\\[\\begin{aligned}\n\\mathbb E\\left[ \\frac{YA}{p(L)} \\right] & = \\mathbb E\\left[\\mathbb E\\left[ \\frac{YA}{p(L)} \\middle\\vert L \\right] \\right] \\\\\n& = \\mathbb E\\left[\\mathbb E\\left[ \\frac{Y_{A=1}A}{p(L)} \\middle\\vert L \\right] \\right] \\\\\n& = \\mathbb E\\left[\\frac{\\mathbb E[Y_{A=1}|L] \\mathbb E[A|L]}{p(L)} \\right] \\\\\n& = \\mathbb E\\left[\\frac{\\mathbb E[Y_{A=1}|L] \\cancel{\\mathbb E[A|L]}}{\\cancel{\\mathbb E[A|L]}} \\right] \\\\\n& = \\mathbb E\\left[\\mathbb E[Y_{A=1}|L]\\right] \\\\\n& = \\mathbb E\\left[Y_{A=1}\\right]. \\\\\n\\end{aligned}\n\\]\nHence we can conclude that the inverse probability of treatment weighting yields an unbiased estimator for the causal effect.\n\n\\(\\square\\)"
  },
  {
    "objectID": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#stabilized-weights",
    "href": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#stabilized-weights",
    "title": "3  Marginal Structural Models",
    "section": "3.5 Stabilized Weights",
    "text": "3.5 Stabilized Weights\nRobins, Hernán, and Brumback go on to say that if levels of \\(A\\) and \\(L\\) are strongly associated, then it is likely that we will see quite large inverse probability of treatment weights. Such undesired variability in our estimated weights suggest that few individuals may inappropriately dominate the pseudopopulation and hence the weighted analysis.\nTo mitigate this, they introduce “stabilized weights” which are written as \\[sw_i = \\frac{Pr(A = a_i)}{Pr(A=a_i | L=l_i)},\\] which are the same weights as before just multiplied by \\(Pr(A=A_i)\\).\nI am suspicious that the reason we’re able to do this trick is because if we refer back to the proof that the original weights provided an unbiased estimator, we saw that \\[\\mathbb E\\left[ \\frac{Y_{A=1}A}{p(L)} \\right] = \\mathbb E\\left[ Y_{A=1} \\right],\\] and if we work the same argument through with the stabilized weights, I think we’d get \\(\\mathbb E\\left[ Y_{A=1} \\mathbb E[A] \\right]\\) instead. However, since \\(\\mathbb E[Y_{A=1}]\\) is the expected value of \\(Y\\) when \\(A=1\\), I think we can say that the prior quantity is equal to \\(\\mathbb E\\left[ Y \\mathbb E[A] \\middle\\vert A = 1\\right] = \\mathbb E\\left[ Y \\middle \\vert A = 1 \\right] = \\mathbb E[ Y_{A=1} ].\\)"
  },
  {
    "objectID": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#time-dependent-treatments",
    "href": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#time-dependent-treatments",
    "title": "3  Marginal Structural Models",
    "section": "3.6 Time-Dependent Treatments",
    "text": "3.6 Time-Dependent Treatments\nReturning to the setting of time-dependent confounding as in Figures 1a-c, let \\(A_k\\) represent the dosage of a treatment on the \\(k\\)th day from start of follow-up, \\(Y\\) is a dichotomous variable measured at the end of follow-up on day \\(K+1\\) , and \\(L_k\\) represents all measured risk factors for the outcome on day \\(k\\). We’ll let \\(\\bar A_k = (A_0, A_1, ..., A_k)\\) be the treatment or exposure history thorugh day \\(k\\) and let \\(\\bar A = \\bar A_K\\).\nGenerally we’ll be more interested in the cumulative effect of dosage (\\(\\sum a_k\\)) rather than specific dosage histories \\(\\bar a\\) when thinking about counterfactuals.\nAssuming no loss to follow-up selection bias or measurement error, we can unbiasedly estimate causal quantities using a logistic regression model\n\\[ \\text{logistic}(Pr[Y=1 | \\bar A = \\bar a]) = \\beta_0 + \\beta_1 \\sum a_k, \\] if treatment is unconfounded.\nHowever, if treatment is confounded, we need to reweight the population by stabilized weights given by\n\\[sw_i = \\frac{\\displaystyle \\prod_{k=0}^K Pr(A_k = a_{ki} | \\bar A_{k-1} = \\bar a_{(k-1)i})}{\n\\displaystyle \\prod_{k=0}^K Pr(A_k = a_{ki} | \\bar A_{k-1} = \\bar a_{(k-1)i}, \\bar L_k = \\bar l_{ki}).\n}\\]"
  },
  {
    "objectID": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#censoring-by-loss-to-follow-up",
    "href": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#censoring-by-loss-to-follow-up",
    "title": "3  Marginal Structural Models",
    "section": "3.7 Censoring by Loss to Follow-Up",
    "text": "3.7 Censoring by Loss to Follow-Up\nThey say that we can also consider censoring at time \\(k\\) (denoted \\(C_k\\)) as another aspect of treatment and re-work our analyses to become “inverse-probability-of-treatment-and-censoring weighted estimators” if we view \\((A_k, C_k)\\) as a joint-treatment at time \\(k\\)."
  },
  {
    "objectID": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#limitations",
    "href": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#limitations",
    "title": "3  Marginal Structural Models",
    "section": "3.8 Limitations",
    "text": "3.8 Limitations\nThe authors state that marginal structural models cannot be used to model the interaction of treatment with a time-varying covariate (so effect modification). For this, they recommend structural nested models to be used.\nAs suggested above, it’s also the case that we cannot use marginal structural models when we have violations to the positivity assumption."
  },
  {
    "objectID": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#important-points-from-the-appendix",
    "href": "2000_Robins_Hernan_and_Brumback/2000_Robins_Hernan_and_Brumback.html#important-points-from-the-appendix",
    "title": "3  Marginal Structural Models",
    "section": "3.9 Important Points from the Appendix",
    "text": "3.9 Important Points from the Appendix\nIf we recall the recommendations from Rosenbaum and Rubin, 1983, it’s worth distinguishing the approach suggested here from the propensity score based approaches previously. The propensity score methods were largely oriented towards either propensity score stratification, propensity score matching, or covariance adjustment for propensity scores. It’s very much worth noting that the inverse of the propensity score is not the same as the inverse probability of treatment proposed here, as the propensity score always models \\(Pr(A=1|L=l)\\) while the probability of treatment is the probability of the treatment a specific unit received, so \\(Pr(A=a_i | L=l_i)\\). In other words, for those units which were treated, the propensity score and the probability of treatment agree, but for untreated units, the probability of the treatment they received (no-treatment) is \\(1-Pr(A=1|L=l_i)\\).\nAs an additional consideration, it’s worth noting that matching or stratification methods could introduce significant bias if there is difficulty finding sufficiently close matches or residual uncontrolled-for intrastratum confounding."
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#introduction",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#introduction",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Introduction",
    "text": "Introduction\nThis paper introduces the reader to the propensity score and shows how, through large and small sample theory, that adjustment for the scalar propensity score is sufficient to remove bias due to the observed covariates.\nThe quantity of fundamental interest is the average treatment effect (presented in their notation):\n\\[\\mathbb E(r_1) - \\mathbb E(r_0),\\] where \\(r_1\\) is the outcome under treatment and \\(r_0\\) is the outcome under no treatment.\nThey introduce balancing scores which are functions \\(b(x)\\) such that \\[x \\perp\\!\\!\\!\\perp z | b(x) \\quad (\\text{or equivalently} \\quad  z \\perp\\!\\!\\!\\perp x | b(x)).\\]\nIn other words, \\(P(Z|X,b(X)) = P(Z|b(X))\\).\nWe define the propensity score to be \\[e(x) = Pr(Z=1|X = x)\\] e.g., the probability of treatment given covariates}, is the propensity score or propensity towards treatment."
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#an-example",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#an-example",
    "title": "2  The Central Role of Propensity Scores",
    "section": "An Example",
    "text": "An Example\nWe might have a situation where age is correlated with assignment to the treatment mechanism.\nDenoting \\(X\\) as age and \\(Z\\) as treatment, consider the following scenario where we set\n\\[X \\sim \\text{Uniform on } \\mathbb N \\cap \\text{ the age range } [19,64]\\] \\[Z \\sim \\text{Bernoulli}(\\underbrace{\\text{logistic}(\\underbrace{\\beta_0 + \\beta_1 \\cdot X}_{\\text{log odds}})}_{\\text{probability scale}})\\] \\[ \\text{where logistic}(x) = \\frac{1}{1+e^{-x}} = \\frac{e^x}{1+e^x}\\]\nIt’s clear that \\(X\\) and \\(Z\\) will be dependent and correlated, but by stratifying on propensity scores estimated via a logistic regression model, we can empirically see an example of\nhow conditioning on propensity scores renders \\(X\\) and \\(Z\\) conditionally independent.\n\n# Dependencies\nlibrary(tidyverse)\n\n# Generate a data.frame of 100 folks with ages from 19-65\ndf <- data.frame(x = sample(x=seq(19,65), replace=TRUE, size = 100))\n\n# Coefficients for our logistic model\nbeta_0 <- -5\nbeta_1 <- 0.1\n\n# Compute the odds of treatment using a logistic function\ndf$e_x <- exp(beta_0 + beta_1 * df$x) / (1 + exp(beta_0 + beta_1 * df$x))\n\n# Assign treatment group based on the computed odds\ndf$z <- rbinom(n = nrow(df), size = 1, prob = df$e_x)\n\n# Fit a logistic regression model \nmodel <- glm(z ~ x, data = df, family = binomial(link=logit))\n\n# Report model estimates\ncoef(model)\n\n# Predicted propensity scores\ndf$propensity_scores <- predict(model, type=\"response\")\n\n# We can confirm these match our intuition — \n# This is just applying the logistic function 1/(1+exp(-x)) to the\n# expanded terms from our regression model.\nall.equal(df$propensity_scores, 1/(1+exp(-(coef(model)[1] + coef(model)[2]*df$x))))\n\n# Plot our age-treatment relationship\nggplot(df, aes(x = x, y = z)) + \n  geom_jitter(width=0.25, height=0.025, alpha = 0.5) + \n  geom_line(data = \n    data.frame(x = seq(18,65,.1), \n      y = predict(model, newdata = data.frame(x = seq(18,65,.1)), type='response')),\n    aes(x = x, y = y),\n    color = 'blue') + \n  xlab(\"Age\") + \n  ylab(\"Treatment, or Treatment Probability\") + \n  ggtitle(\"Distribution of Treatment Assignment by Age and Logistic Model\") + \n  theme_bw()\n\n\n# Divide the data into bins based on the propensity score\ndf$e_bin <- cut(df$e_x, breaks = seq(0, 1, by = 0.1))\n\n# Calculate the mean age by propensity score in\nmean_x_by_bin <- df |> group_by(e_bin, z) |> summarize(x = mean(x))\n\n# Show age by propensity score bins and treatment\nggplot(df, aes(x = e_bin, y = x, color = as.factor(z))) +\n  geom_jitter(width=.25, height = .05, alpha = 0.5, size = 1) +\n  geom_line(data = mean_x_by_bin, aes(group = z)) +\n  labs(title = \n    \"Balance Check: Mean Age (Line) by Propensity Score Bin and Treatment Status\"),\n       x = \"Propensity Score Bin\",\n       y = \"Age\",\n       color = \"Treatment Status\")\n\n\n\n\n\n\nThe distribution of treatment assignment by age and a fit logistic model.\n\n\n\n\n\n\n\n\n\nA balance check showing that after stratifying by the propensity scores, age and assignment to treatment are independent."
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-1",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-1",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Theorem 1",
    "text": "Theorem 1\n\\(e(X)\\) is a balancing score. That is, \\[X \\perp\\!\\!\\!\\perp Z | e(X).\\]\nProof. We want to show that \\[Pr(Z = 1 | X, e(X)) = Pr(Z = 1 | e(X)).\\]\nSince \\(e(x)\\) is a function of \\(x\\), we have that \\[Pr(Z = 1 | X, e(X)) = Pr(Z = 1 | X = X) = e(X).\\]\nWhat remains is to show that \\(Pr(Z = 1 | e(X)) = e(X)\\).\nBy the definition of probability and the law of iterated expectation, \\[\\begin{aligned}\nPr(Z = 1 | e(X)) & = \\mathbb E[Z = 1 | e(X)] \\quad \\text{ (by definition of probability) } \\\\\n& = \\mathbb E[\\mathbb E(Z = 1|X) | e(X)] \\quad (\\star) \\\\\n& = \\mathbb E[ e(X) | e(X) ] \\\\\n& = e(x) \\quad \\text{(by the law of iterated expectations)}\n\\end{aligned}\\]\nThe \\((\\star)\\) step can be justified two ways, either rhetorically or more rigorously:\n\nRhetorically: With respect to the inside term, we can apply extra conditioning by \\(X = x\\) since we’re going to compute the outer expectations conditioned on \\(e(X)\\) and thus across the \\(X\\) values that satisfy \\(X = x \\in e^{-1}(x)\\).\nMore rigorously: \\[ \\begin{aligned}\n    \\mathbb E[Z = 1 | e(X')] & = \\mathbb E[Z = 1 | X \\in e^{-1}(X')] \\\\\n    & = \\frac{1}{Pr(X \\in e^{-1}(X'))} \\int z Pr(Z = 1, X \\in e^{-1}(X')) dz \\\\\n    & = \\frac{1}{Pr(X \\in e^{-1}(X'))} \\int z \\int_{x \\in e^{-1}(X')} Pr(Z = 1 | X = x) dx dz \\\\\n    & = \\mathbb E[\\mathbb E[Z = 1 | X ] | X \\in e^{-1}(X')] \\\\\n    & = \\mathbb E[\\mathbb E[Z = 1 | X ] | e(X')] \\\\\n    & = \\text{(continue from above)}\n    \\end{aligned}\\]\n\nThus \\[Pr(Z = 1 | X, e(X)) = e(X) = Pr(Z = 1 | e(X)).\\]\n\n\\(\\square\\)"
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-2",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-2",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Theorem 2",
    "text": "Theorem 2\nLet \\(b(x)\\) be a function of \\(x\\). Then \\(b(x)\\) is a balancing score, that is \\[x \\perp\\!\\!\\!\\perp z | b(x)\\] if and only if \\(b(x)\\) is finer than \\(e(x)\\) in the sense that \\(e(x) = f(b(x))\\) for some function \\(f\\).\nProof. (\\(\\leftarrow\\)) First we show that if \\(b(x)\\) is finer than \\(e(x)\\) then it is a balancing score.\nWe want to show that \\[ Pr(Z = 1 | X, b(X)) \\stackrel{\\text{claim}}{=} Pr(Z = 1 | b(X))\\]\nSince the left hand side is easily understood to be \\(e(x)\\) since \\(b(X)\\) is a function of \\(X\\), it is then sufficient to show that \\[Pr(Z=1|b(x)) = e(x).\\]\nNow we rewrite the left-hand-side as follows: \\[Pr(Z=1|b(x)) = \\mathbb E[Z=1|b(X)] = \\mathbb E[\\mathbb E[Z=1|X]|b(X)] = \\mathbb E[e(x)|b(x)].\\]\nThe next step of Rosenbaum and Rubin’s is to claim that \\[\\mathbb E[e(X) | b(X) = b(x)] = e(x).\\]\nThe most straightforward way to see this is to start by noting that if we fix \\(X=x\\), then any function of \\(X\\) as a random variable also becomes fixed, so that \\(\\mathbb E[f(X)|X=x] = f(x)\\). In our case, we have that \\(e(x) = f(b(x))\\), so \\(\\mathbb E[e(x)|b(x)] = \\mathbb E[f(b(X))|b(X)=b(x)] = f(b(x)) = e(x)\\).\nAs a result, we’ve shown that \\[\\mathbb E[e(x)|b(x)] = Pr(Z = 1|b(x)) = e(x),\\] which concludes this direction of the proof showing that if \\(b(x)\\) is finer than \\(e(x)\\) then it is a balancing score.\n\\[ \\exists f \\colon e(x) = f(b(x)) \\Longrightarrow X \\perp\\!\\!\\!\\perp Z | b(x).\\]\n(\\(\\rightarrow\\)) Moving on, we now prove the converse direction by contradiction. Suppose that we have \\(b(x)\\), a balancing score such that \\(X \\perp\\!\\!\\!\\perp Z | b(x)\\), but \\(b(x)\\) is not finer than \\(e(x)\\) so we have \\(\\exists x_1, x_2 \\ni e(x_1) \\neq e(x_2) \\text{ and } b(x_1) = b(x_2)\\).\nWe know by applying the definition of \\(e(\\cdot)\\) that \\[Pr(Z = 1 | X = x_1) \\neq Pr(Z = 1 | X = x_2).\\] However, if \\(X \\perp\\!\\!\\!\\perp Z | b(x)\\), then we should have that\n\\[Pr(Z = 1 | X = x_1, b(x_1)) = Pr(Z=1 | b(x_1)), \\quad \\text{ and }\\] \\[Pr(Z = 1 | X = x_2, b(x_2)) = Pr(Z=1 | b(x_2)).\\]\nSince \\(b(x_1) = b(x_2)\\), we also then know that \\[Pr(Z=1 | b(x_1)) = Pr(Z=1 | b(x_2)),\\] but this would imply that \\[e(x_1) = Pr(Z = 1 | X = x_1, b(x_1)) = Pr(Z = 1 | X = x_2, b(x_2)) = e(x_2),\\] since \\(Pr(Z|X,f(X)) = Pr(Z|X)\\) for any function \\(f\\). This establishes a contradiction to our assumption that \\(e(x_1) \\neq e(x_2)\\).\nThus if \\(b(x)\\) is a balancing function then it must be finer than \\(e(x)\\). \\[X \\perp\\!\\!\\!\\perp Z | b(x) \\Longrightarrow e(x) = f(b(x)).\\]\n\n\\(\\square\\)"
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#section",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#section",
    "title": "2  The Central Role of Propensity Scores",
    "section": "",
    "text": "Definition. We say that treatment assignment is strongly ignorable given a vector of covariates \\(v\\) if and only if \\[(r_1,r_0) \\perp\\!\\!\\!\\perp z | v, \\quad 0 < Pr(Z=1|v) < 1.\\]"
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-3",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-3",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Theorem 3",
    "text": "Theorem 3\nIf treatment assignment is strongly ignorable given \\(x\\), then it is strongly ignorable given any balancing score \\(b(x)\\); that is, \\[(r_1, r_0) \\perp\\!\\!\\!\\perp Z | X\\] and \\[0 < Pr(Z=1 | X) < 1\\] for all \\(x\\) imply \\[(r_1, r_0) \\perp\\!\\!\\!\\perp Z | b(X)\\] and \\[0 < Pr(Z = 1 | b(X)) < 1\\] for all \\(b(X)\\).\nProof. It is clear that if \\(0 < Pr(Z = 1|x) < 1\\) for all values of \\(x\\), then there is no such value of \\(x\\) where conditioning on \\(b(x)\\) would push the quantity \\(Pr(Z=1|b(x))\\) outside the interval \\((0,1)\\).\nWhat remains then is to show that \\((r_1, r_0) \\perp\\!\\!\\!\\perp z | b(x)\\), or rewritten that \\[Pr(Z=1 | r_1, r_0, b(x)) = Pr(Z=1 | b(x)),\\] which, if we recall the proof to Theorem 2, we have shown \\[ = e(x).\\]\nIn order to show the claimed equality, we rewrite the probability of treatment given \\(r_1, r_0,\\) and \\(b(x)\\) as the expected value of \\(Pr(Z=1 | r_1, r_0, X)\\) conditioned on \\(b(x)\\). We then have, by the assumption that \\((r_1, r_0) \\perp\\!\\!\\!\\perp Z | X\\),\n\\[\\begin{aligned}\nPr(Z = 1 | r_1, r_0, b(x)) & = \\mathbb E[Pr(Z=1|r_1,r_0,X)|b(x)] \\\\\n& = \\mathbb E[Pr(Z=1|X)|b(x)] \\\\\n& = \\mathbb E[e(X)|b(x)] = e(x).\n\\end{aligned}\\]\n\n\\(\\square\\)"
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-4",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-4",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Theorem 4",
    "text": "Theorem 4\nSuppose treatment assignment is strongly ignorable and \\(b(x)\\) is a balancing score. Then the expected difference in observed responses to the two treatments at \\(b(x)\\) is equal to the average treatment effect at \\(b(x)\\), that is,\n\\[\\mathbb E[r_1 | b(x), Z= 1] - \\mathbb E[r_0 | b(x), Z= 0] = \\mathbb E[r_1 - r_0 | b(x)].\\]\nProof. If a randomly selected treated unit (\\(Z = 1\\)) is compared to a randomly selected control unit (\\(Z = 0\\)), the expected difference in outcome is \\[\\mathbb E[r_1 | Z = 1] - \\mathbb E[r_0 | Z=0].\\]\nThis expression does not equal \\(\\mathbb E[r_1] - \\mathbb E[r_0]\\) in general because we do not observe \\(r_1\\) for untreated units and vice-versa and instead only observe the conditional distribution of \\(r_t\\) given \\(Z = t\\).\nWe introduce a two-stage sampling procedure now, where first we sample a vector of covariates \\(x\\) and then sample both treated and control units that have covariates equal to \\(x\\). The expected difference is now \\[\\mathbb E_{x} [ E[r_1 | X=x, Z=1] - \\mathbb E[r_0 | X=x, Z=0]],\\] where \\(\\mathbb E_{x}\\) denotes expectation with respect to the distribution of covariates \\(X\\). If treatment assignment is strongly ignorable, then the above is equal to \\[ \\mathbb E_x [E[r_1|x] - E[r_0|x]],\\] which is the average treatment effect.\nNow suppose we alter the two-stage sampling procedure to sample a value of \\(b(x)\\) instead of a vector of covariate levels. Given strongly ignorable treatment assignment, it follows from Theorem 3 that\n\\[\\mathbb E[r_1 | b(x), Z = 1] - \\mathbb E[r_0 | b(x), Z=0] = \\mathbb E[r_1 | b(x)] - \\mathbb E[r_0 | b(x)].\\]\nFrom this it follows that\n\\[\\begin{aligned} \\mathbb E_{b(x)} [ \\mathbb E[r_1| b(x), Z=1] - \\mathbb E[r_0 | b(x), Z = 0]] &\n= \\mathbb E_{b(x)} [ \\mathbb E[r_1 | b(x)] - \\mathbb E[r_0 | b(x)]] \\\\\n& = \\mathbb E[r_1 - r_0]. \\end{aligned}\\]\nTo quote:\n\nIn words, under strongly ignorable treatment assignment, units with the same value of the balancing score \\(b(x)\\) but different treatments can act as controls for each other, in the sense that the expected difference in their responses equals the average treatment effect.\n\n\n\\(\\square\\)"
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#corollaries",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#corollaries",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Corollaries",
    "text": "Corollaries\nParaphrasing: These theorems provide a rigorous justification for the estimation of average treatment effects via either pair matching on balancing scores or by estimating those treatment effects within strata of equal (or similar) balancing scores.\n\nCorollary 4.3. Covariance adjustment on balancing scores. Suppose treatment assignment is strongly ignorable, so that in particular \\(\\mathbb E[r_t|Z = t, b(x)] = \\mathbb E[r_t|b(x)]\\) for balancing score \\(b(x)\\). Further suppose that the conditional expectation of \\(r_t\\) given \\(b(x)\\) is linear: \\[\\mathbb E[r_t | Z=t,b(x)] = \\alpha_t + \\beta_t b(x) \\quad (t=0,1).\\] Then the estimator \\[(\\hat \\alpha_1 - \\hat \\alpha_0) + (\\hat \\beta_1 - \\hat \\beta_0)b(x)\\] is conditionally unbiased given \\(b(x_i)\\) for the treatment effect at \\(b(x)\\), namely \\(\\mathbb E[r_1-r_0|b(x)]\\), if \\(\\hat \\alpha_t\\) and \\(\\hat \\beta_t\\) are conditionally unbiased estimators of \\(\\alpha_t\\) and \\(\\beta_t\\) such as least squares estimators. Moreover \\[(\\hat \\alpha_1 - \\hat \\alpha_0) + (\\hat \\beta_1 - \\hat \\beta_0) \\bar b,\\] where \\(\\bar b = n^{-1} \\sum b(x_i)\\) is unbiased for the average treatment effect if the units in the study are a simple random sample from the population.\n\nCorollary 4.3 feels particularly different from corollary 4.1 and 4.2 (which are only summarized above) to me in that the above simulation (to me) clearly demonstrates how pair-matching and stratification on balancing scores would work. However, the covariate adjustment proposed in corollary 4.3 feels like something else, so I thought having some simulation code to demonstrate it made sense.\n\n# 1. Generate data\nn <- 200\nx <- rnorm(n)\nb_x <- 1 / (1 + exp(-x))  # a simple logistic propensity score\n\n# 2. Simulate treatment assignments\nz <- rbinom(n, 1, b_x)\n\n# 3. Simulate potential outcomes\nalpha_0 <- 2\nalpha_1 <- 3\nbeta_0 <- 1.5\nbeta_1 <- 2\nr_0 <- alpha_0 + beta_0 * b_x + rnorm(n)\nr_1 <- alpha_1 + beta_1 * b_x + rnorm(n)\n\n# Observed outcomes\nr <- z * r_1 + (1 - z) * r_0\ndf <- data.frame(b_x = b_x, z = z, r = r)\n\n# 4. Use linear regression to estimate parameters\nmodel_0 <- lm(r ~ b_x, data = df[z == 0,])\nmodel_1 <- lm(r ~ b_x, data = df[z == 1,])\n\nhat_alpha_0 <- coef(model_0)[1]\nhat_alpha_1 <- coef(model_1)[1]\nhat_beta_0 <- coef(model_0)[2]\nhat_beta_1 <- coef(model_1)[2]\n\n# 5. Compute the estimator\nb_bar <- mean(b_x)\nATE_est <- (hat_alpha_1 - hat_alpha_0) + (hat_beta_1 - hat_beta_0) * b_bar\n\nprint(ATE_est)\n\n(Intercept) \n   1.438144 \n\n# 6. Compare to the true average treatment effect\ntrue_ATE <- (alpha_1 - alpha_0) + (beta_1 - beta_0) * b_bar\nprint(true_ATE)\n\n[1] 1.239088\n\n# 7. Bootstrap to estimate SE of ATE_est\n\nB <- 1000  # number of bootstrap samples\nATE_boot <- numeric(B)\n\nfor (i in 1:B) {\n  # Resample data with replacement\n  bootstrap_indices <- sample(1:n, n, replace = TRUE)\n  x_b <- x[bootstrap_indices]\n  z_b <- z[bootstrap_indices]\n  r_b <- r[bootstrap_indices]\n  b_x_b <- b_x[bootstrap_indices]\n  df <- data.frame(r_b = r_b, b_x_b = b_x_b, z_b = z_b)\n  \n  # Use linear regression to estimate parameters for bootstrapped data\n  model_0_b <- lm(r_b ~ b_x_b, data = df[z_b == 0,])\n  model_1_b <- lm(r_b ~ b_x_b, data = df[z_b == 1,])\n  \n  hat_alpha_0_b <- coef(model_0_b)[1]\n  hat_alpha_1_b <- coef(model_1_b)[1]\n  hat_beta_0_b <- coef(model_0_b)[2]\n  hat_beta_1_b <- coef(model_1_b)[2]\n  \n  # Compute the estimator for bootstrapped data\n  b_bar_b <- mean(b_x_b)\n  ATE_boot[i] <- (hat_alpha_1_b - hat_alpha_0_b) + (hat_beta_1_b - hat_beta_0_b) * b_bar_b\n}\n\n# Standard error is the standard deviation of the bootstrapped estimates\nSE_ATE_boot <- sd(ATE_boot)\nmean_ATE_boot <- mean(ATE_boot)\n\nprint(SE_ATE_boot) # print standard error for bootstrap estimated ATE\n\n[1] 0.1577429\n\nprint(mean_ATE_boot) # check bootstrap estimated ATE resembles above estimate\n\n[1] 1.433139\n\n\n\n# 9. Visualizations to Aid Intuition\nggplot(df, aes(x=b_x, fill=as.factor(z), color = as.factor(z))) +\n  geom_density(alpha = 0.15) +\n  geom_dotplot(\n    alpha = 0.5,\n    stackgroups = TRUE,\n    method = \"dotdensity\",\n    binpositions = 'all',\n    binwidth = .022\n  ) + \n  labs(title=\"Distribution of Propensity Scores by Treatment Group\",\n       x=\"Propensity Score\",\n       y=\"Frequency\",\n       fill=\"Treatment Group\",\n       color=\"Treatment Group\") + \n  scale_fill_manual(\n    values = c('0' = 'dodgerblue', '1' = 'orange'),\n    labels = c(expression(r[0]), expression(r[1]))\n  ) + \n  scale_color_manual(\n    values = c('0' = 'dodgerblue', '1' = 'orange'),\n    labels = c(expression(r[0]), expression(r[1]))\n  ) + \n  theme_bw() + \n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\nggplot(df, aes(x = b_x, y = r, color = factor(z))) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = expression(paste(\n      \"Outcomes \", r[0], \" and \", r[1], \" vs. Propensity Score\"\n    )),\n    x = \"Propensity Score\",\n    y = expression(paste(\"Outcome: \", r[0], \" or \", r[1])),\n    color = \"Outcome Type\"\n  ) +\n  annotate(\n    geom = 'segment',\n    xend = b_bar,\n    yend = hat_alpha_1 + hat_beta_1 * b_bar,\n    x = b_bar,\n    y = hat_alpha_0 + hat_beta_0 * b_bar,\n    arrow = arrow(ends = 'both', length = unit(2, 'mm'))\n  ) +\n  annotate(\n    geom = 'label',\n    x = b_bar + .16,\n    y = mean(c(hat_alpha_0, hat_alpha_1)) + mean(c(hat_beta_0, hat_beta_1)) * b_bar + .15,\n    label = 'average treatment effect',\n    alpha = 0.8\n  ) +\n  scale_color_manual(\n    values = c('0' = 'dodgerblue', '1' = 'orange'),\n    labels = c(expression(r[0]), expression(r[1]))\n  ) +\n  theme_bw()"
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#claims-about-matching",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#claims-about-matching",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Claims about matching",
    "text": "Claims about matching\nRosenbaum and Rubin continue in their section on applications of propensity scores to observational studies to make the following arguments about the superiority of matching techniques to model-based adjustment ones in estimating average treatment effects.\nThey claim\n\nMatched treated and control pairs allow relatively unsophisticated researchers to do meaningful analysis by performing pair-comparisons.\nMatching methods should have lower variance estimates of treatment effects compared to covariance based methods because matched samples should be more similar than in random samples.\nModel-based adjustment on matched samples should be more robust to the assumed form of the underlying model than model-based adjustement on random samples because of reduced reliance on model extrapolations.\nIn settings with small numbers of treated observations, large reservoirs of control observations, and large numbers of potential confounders, those confounding variables are more likely to be able to be adjusted for by matched sampling than regression adjustment."
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#section-1",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#section-1",
    "title": "2  The Central Role of Propensity Scores",
    "section": "",
    "text": "Definition. The initial bias in \\(X\\) is defined as the quantity \\[B = \\mathbb E[X|Z=1] - \\mathbb E[X|Z=0]\\]\nand the expected bias in \\(X\\) in matched samples is \\[ B_m = \\mathbb E[X|Z=1] - \\mathbb E_m [X|Z=0]\\] where the subscript \\(m\\) indicates the distribution in matched samples.\nIf \\(B_m = \\gamma B\\) for some scalar \\(\\gamma\\) with \\(0 < \\gamma < 1\\) then matching reduces bias in each coordinate of \\(X\\) is reduced by \\(100(1-\\gamma)\\)% and we say that the matching method is equal percent bias reducing."
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-6",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-6",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Theorem 6",
    "text": "Theorem 6\nLet \\(b = b(x)\\) be a balancing score. For any matching method that uses \\(b\\) alone to match each treated unit with a control unit, the reduction in bias is \\[B - B_m = \\int \\mathbb E[X|b] \\{ \\text{Pr}_m(b|z=0) - \\text{Pr}(b|z = 0) \\} db,\\] where \\(\\text{Pr}_m(b | z = 0)\\) denotes the distribution of \\(b\\) in matched samples from the control group.\nProof. Using the definitions introduced immediately prior, we have that \\[\\begin{aligned} B-B_m = \\int \\{ E_m&[X | Z = 0, b) \\text{Pr}_m(b|Z=0) \\\\\n& - \\mathbb E[X|Z=0,b) \\text{Pr}(b|Z=0) \\} db.\\end{aligned}\\] For any matching method satisfying the condition of the theorem \\[\\mathbb E_m[X|Z=0,b] = \\mathbb E[X|Z=0,b]\\] because any matching method using \\(b\\) alone to match units alters the marginal distribution of \\(b\\) in the control group, \\(Z = 0\\), but does not alter the conditional distribution of \\(x\\) given \\(b\\) in the control group. However, by theorem 2, \\[\\mathbb E[X|Z=0,b] = \\mathbb E[X|b].\\] Substitution into the first equation yields the result.\n\n\\(\\square\\)"
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#corollary-6.1",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#corollary-6.1",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Corollary 6.1",
    "text": "Corollary 6.1\nIf \\(\\mathbb E[X|b] = \\alpha + \\beta f(b)\\) for some vectors \\(\\alpha\\) and \\(\\beta\\) and some scalar-valued function \\(f(\\cdot)\\), then matching on \\(b\\) alone is equal percent bias reducing.\nProof. The percent reduction in bias for the \\(i\\)th coordinate of \\(X\\) is:\n\\[ 100 \\frac{\\beta_i [\\mathbb E_m(f(b)|Z=0) - \\mathbb E(f(b)|Z=0)]}{\\beta_i [\\mathbb E(f(b)|Z=1) - \\mathbb E(f(b)|Z=0)]},\\] which is independent of \\(i\\) as required (because \\(\\beta_i\\) cancels from the numerator and denominator)."
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-7",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#theorem-7",
    "title": "2  The Central Role of Propensity Scores",
    "section": "Theorem 7",
    "text": "Theorem 7\nLet \\(I_s\\) be the set of values of a balancing score which make up subclass \\(s\\) (\\(s = 1, ..., S\\)), so that \\(b(a) \\in I_s\\) implies that the units with \\(x = a\\) fall in subclass \\(s\\). Suppose the weight applied to subclass \\(s\\) in direct adjustment is \\(w_s\\).\nThe bias in \\(x\\) after direct adjustment for the subclasses \\((I_s, s = 1, ..., S)\\) is \\[\\begin{aligned}B_i = \\sum_{s = 1}^S w_s \\int \\mathbb E(X|b) & \\{ \\text{Pr}(b|Z=1, b \\in I_s) \\\\\n& - \\text{Pr}(b|Z=0, b \\in I_s \\} db,\\end{aligned}\\] where \\(b = b(x)\\).\nFor pedagogical aid, let’s go back to our first example and consider what bias results from dividing the dataset into varying fineness of quantile bins (tertiles, quintiles, and deciles) and observe how bias decreases as we increase the fineness of our bins. In this simulation, we use 1000 observations to ensure we have large enough sample sizes in each bin.\n\n\n\n\n# Generate a data.frame of 1000 folks with ages from 19-65\ndf <- data.frame(x = sample(x=seq(19,65), replace=TRUE, size = 1000))\n\n# Coefficients for our logistic model\nbeta_0 <- -5\nbeta_1 <- 0.1\n\n# Compute the odds of treatment using a logistic function\ndf$e_x <- exp(beta_0 + beta_1 * df$x) / (1 + exp(beta_0 + beta_1 * df$x))\n\n# Assign treatment group based on the computed odds\ndf$z <- rbinom(n = nrow(df), size = 1, prob = df$e_x)\n\n# Calculate the initial bias in x\ninitial_bias_in_x <-\n  df %>% filter(z == 1) %>% summarize(x = mean(x)) -\n  df %>% filter(z == 0) %>% summarize(x = mean(x))\n\n# Describe initial bias\ncat(paste0(\"Initial bias in x (age): \", round(initial_bias_in_x, 1), \"\\n\"))\n\nInitial bias in x (age): 15.5\n\ncat(stringr::str_wrap(\n  paste0(\n    \"In other words, age is on average \",\n    round(initial_bias_in_x, 1),\n    \" years higher in the treated group than the untreated group\"\n  ),\n  width = 80\n))\n\nIn other words, age is on average 15.5 years higher in the treated group than\nthe untreated group\n\n# Consider tertile, quantile, and decile subclassification\nfor (n in c(3, 5, 10)) {\n  # Divide propensity scores into S subclasses.\n  df$quantile <- cut(df$e_x, quantile(df$e_x, seq(0,1,length.out=n)), include.lowest = TRUE)\n  \n  # expectation of x by quantile of propensity score and by treatment status\n  E_x_by_subclass <- df %>% \n    group_by(quantile, z) %>%\n    summarise(E_x_b = mean(x))\n  \n  # pivot wider so we can subtract\n  E_x_by_subclass <- tidyr::pivot_wider(E_x_by_subclass,\n    id_cols = 'quantile', \n    values_from = 'E_x_b',\n    names_from = z)\n  \n  # rename columns from 1 and 0 to be more descriptive\n  E_x_by_subclass <-\n    rename(\n      E_x_by_subclass,\n      E_x_given_subclass_and_z1 = `1`,\n      E_x_given_subclass_and_z0 = `0`\n    )\n  \n  # use equal weighting for each subclass\n  w_s <- 1/n\n  \n  # calculate the bias in x within the Is substrata \n  B_s <- sum(w_s * with(E_x_by_subclass, (E_x_given_subclass_and_z1 - E_x_given_subclass_and_z0)))\n  \n  cat(paste0(\"Bias in x (age) after adjusting for \", n, \" subclasses is \", round(B_s, 1), '\\n'))\n}\n\nBias in x (age) after adjusting for 3 subclasses is 3\nBias in x (age) after adjusting for 5 subclasses is 0.8\nBias in x (age) after adjusting for 10 subclasses is 0.1"
  },
  {
    "objectID": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#my-conclusions",
    "href": "1983_Rosenbaum_and_Rubin/1983_Rosenbaum_and_Rubin.html#my-conclusions",
    "title": "2  The Central Role of Propensity Scores",
    "section": "My Conclusions",
    "text": "My Conclusions\nThe first comment I would make is that for anyone looking to follow the details of the proofs, the presentation in Chapters 12 and 13 of Causal Inference for Statistics, Social, and Biomedical Sciences by Guido W. Imbens and Donald B. Rubin is much more introductory, detailed and I found the notation more clear in terms of what is a random variable vs. being treated as a fixed value.\nI did not realize to what an extent this paper would be a mini-treatise on the advantages of matching as opposed to covariance-adjustment methods when using propensity scores.\nI’m very happy to feel that I’m now up to speed on what the proofs behind the scenes are when people talk about propensity score matching or regression methods that incorporate propensity scores. I’ll have to keep reading as I’ve just started to discover some literature around the deficiencies of propensity score matching, which I now feel prepared to tackle given my newfound acquaintance with the subject matter. For example of criticisms, see:\n\nKing, G., & Nielsen, R. (2019). Why Propensity Scores Should Not Be Used for Matching. Political Analysis, 27(4), 435-454. doi:10.1017/pan.2019.11\n\nMy sense is that it’s been a fruitful task for me to work through this paper filling in the proof details that weren’t immediately clear to me and writing simulation code to aid learning as I went along. I’m hopeful that this knowledge will pay off as I move towards more complex subjects, especially things like  targeted learning or super-learners."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Readings in Causal Inference, Fall 2023",
    "section": "Introduction",
    "text": "Introduction\nDuring the Fall 2023 I’m doing a reading-based independent study and writing up my notes to share here from some classic and modern texts in causal inference with a particular interest on a few subtopics including 1) complex mediators, 2) the role of semiparametric methods, and 3) doubly-robust learning.\n\n\n\n\n\n\nReading List for the Semester\n\n\n\n\n\n\n\n\nArticle Reference\nLink to Article/Book\n\n\n\n\nRosenbaum, P. R., & Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1), 41-55.\nArticle\n\n\nRobins, J. M., & Ritov, Y. (1997). Toward a curse of dimensionality appropriate (CODA) asymptotic theory for semi-parametric models. Statistics in medicine, 16(3), 285-319.\nArticle\n\n\nRobins, J. M., Hernán, M. Á., & Brumback, B. (2000). Marginal structural models and causal inference in epidemiology. Epidemiology, 11(5), 550-560.\nArticle\n\n\nDawid, A. P. (2000). Causal inference without counterfactuals. Journal of the American Statistical Association, 95(450), 407-424.\nArticle\n\n\nPearl, J. (2001). Direct and indirect effects. Proceedings of the seventeenth conference on uncertainty in artificial intelligence.\nArticle\n\n\nZhang, Z., & Rubin, D. B. (2003). Estimation of causal effects via principal stratification when some outcomes are truncated by ‘death’. Journal of Educational and Behavioral Statistics, 28(4), 353-368.\nArticle\n\n\nRubin, D. B. (2005). Causal inference using potential outcomes: Design, modeling, decisions. Journal of the American Statistical Association, 100(469), 322-331.\nArticle\n\n\nHernán, M. A., & Robins, J. M. (2006). Instruments for causal inference: an epidemiologist’s dream?. Epidemiology, 17(4), 360-372.\nArticle\n\n\nShalizi, C. R., & Thomas, A. C. (2010). Homophily and contagion are generically confounded in observational social network studies. Sociological methods & research, 40(2), 211-239.\nArticle\n\n\nVan der Laan, M. J., & Rose, S. (2011). Targeted Learning: Causal Inference for Observational and Experimental Data. Springer.\nBook\n\n\nPeng, R. D. (2011). Reproducible research in computational science. Science, 334(6060), 1226-1227.\nArticle\n\n\nTchetgen Tchetgen, E. J., & Shpitser, I. (2012). Semiparametric theory for causal mediation analysis: efficiency bounds, multiple robustness and sensitivity analysis. The Annals of Statistics, 40(3), 1816-1845.\nArticle\n\n\nPearl, J. (2012). The causal mediation formula—a guide to the assessment of pathways and mechanisms. Prevention science, 13(4), 426-436.\nArticle\n\n\nTchetgen Tchetgen, E. J. (2013). Identification and estimation of survivor average causal effects. Biometrika, 100(2), 503-518.\nArticle\n\n\nTchetgen Tchetgen, E. J. (2014). The control outcome calibration approach for causal inference with unobserved confounding. The American Statistician, 68(1), 27-32.\nArticle\n\n\nVanderWeele, T. J., & Tchetgen Tchetgen, E. J. (2014). Mediation analysis with time varying exposures and mediators. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 76(3), 523-545.\nArticle\n\n\nVanderWeele, T. J. (2015). Explanation in causal inference: methods for mediation and interaction. Oxford University Press.\nBook\n\n\nImbens, G. W., & Rubin, D. B. (2015). Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.\nBook\n\n\nPeters, J., Janzing, D., & Schölkopf, B. (2017). Elements of causal inference: foundations and learning algorithms. MIT press.\nBook\n\n\nRobins, J. M., Sued, M., Lei, G., & Mínguez, D. (2017). Comment: The self-controlled case series method - An innovative design for home and online randomized controlled trials. Statistical Science, 32(2), 264-267.\nArticle\n\n\nHernán, M. A., & Robins, J. M. (2018). Causal Inference. Chapman & Hall/CRC.\nBook\n\n\nChernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., & Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21(1), C1-C68.\nLink\n\n\n\n\n\n\nSupplemental Articles\nLink to Article\n\n\n\n\nLu Cheng, Ruocheng Guo, and Huan Liu. 2022. Causal Mediation Analysis with Hidden Confounders. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (WSDM ’22). Association for Computing Machinery, New York, NY, USA.\nArticle\n\n\nZhang, Z., Zheng, W., & Albert, J. M. (2019). High-dimensional mediation analysis with latent variables in randomized clinical trials. Statistical Methods in Medical Research, 28(10-11), 3186-3200.\nArticle\n\n\nDerkach A, Pfeiffer RM, Chen TH, Sampson JN. High dimensional mediation analysis with latent variables. Biometrics. 2019 May 5.\nArticle\n\n\nZeng P, Shao Z, Zhou X. Statistical methods for mediation analysis in the era of high-throughput genomics: Current successes and future challenges. Computational and Structural Biotechnology Journal. 2021.\nArticle\n\n\nEric J. Tchetgen Tchetgen. Ilya Shpitser. “Semiparametric theory for causal mediation analysis: Efficiency bounds, multiple robustness and sensitivity analysis.” Ann. Statist. June 2012. https://doi.org/10.1214/12-AOS990\nArticle\n\n\nPeters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). Deep contextualized word representations. arXiv preprint arXiv:1802.05365.\nArticle\n\n\nNima S Hejazi and others, Nonparametric causal mediation analysis for stochastic interventional (in)direct effects, Biostatistics, July 2023. Article\nArticle\n\n\nHernán, M., Taubman, S. Does obesity shorten life? The importance of well-defined interventions to answer causal questions. Int J Obes 32 (Suppl 3), S8–S14 (2008). https://doi.org/10.1038/ijo.2008.82\nArticle\n\n\nPeters, J., Mooij, J. M., Janzing, D., & Schölkopf, B. (2014). Causal discovery with continuous additive noise models.\nArticle\n\n\nMooij, J. M., Peters, J., Janzing, D., Zscheischler, J., & Schölkopf, B. (2016). Distinguishing cause from effect using observational data: methods and benchmarks. The Journal of Machine Learning Research.\nArticle"
  },
  {
    "objectID": "index.html#writeups",
    "href": "index.html#writeups",
    "title": "Readings in Causal Inference, Fall 2023",
    "section": "Writeups",
    "text": "Writeups\n\nWeek 1: The Central Role of the Propensity Score in Observational Studies for Causal Effects by Paul R. Rosenbaum and Donald B. Rubin (1983), Biometrika\nHTML  PDF\n\nWeek 2a: Marginal Structural Models for Causal Inference by James M. Robin, Miguel Ángel Hernán, and Babette Brumback (2000), Epidemiology\nHTML  PDF\n\nWeek 2b: Causal Inference Without Counterfactuals  by Alexander Phillip Dawid (2000). JASA\nHTML PDF"
  },
  {
    "objectID": "2000_Dawid/2000_Dawid.html",
    "href": "2000_Dawid/2000_Dawid.html",
    "title": "4  Causal Inference Without Counterfactuals",
    "section": "",
    "text": "5 Responses"
  },
  {
    "objectID": "2000_Dawid/2000_Dawid.html#types-of-causal-inference",
    "href": "2000_Dawid/2000_Dawid.html#types-of-causal-inference",
    "title": "4  Causal Inference Without Counterfactuals",
    "section": "Types of Causal Inference",
    "text": "Types of Causal Inference\nDawid draws our attention to the difference in nature between two types of questions, which can be characterized by archetypal examples.\n\n“I have a headache. Will it help if I take aspirin?”\n“My headache has gone. Was it because I took aspirin?”\n\nWhile Dawid contrasts these as being about “effects of causes” and “causes of effects,” I find that language is a little bit tricky to follow. Perhaps it is because of my prior knowledge, but I immediately recast these in my mind into the language of “token” and “type” causation, where token causation refers to causal inference with respect to a specific event and type causation refers to causal inference regarding trends in events. In other words, we could take climate related events as an example: “Did climate change cause this storm?” and “Does climate change increase storm intensity?” The former is an example of token causation and in general is thought by many to be much harder to establish. The latter is an example of a question about type causation and is more firmly in the realm of what we usually think of when we think about observational causal inference questions.\nIn the case of Dawid’s examples, I view question 1 as being a question of type causation because at-best we can apply our knowledge about trends in outcomes under aspirin treatment and non-treatment to make some prediction about what might happen in the future under aspirin treatment and non-treatment circumstances. Meanwhile, I view question 2 as a question of token causation: without knowing much more, it’s hard to know if the person in question was simply dehydrated and the water they drank with their aspirin was the more causally significant explanatory variable or perhaps the headache just went away on its own.\nLater on, Dawid has this to say about what I would call inference regarding token causation:\n\nNo amount of wishful thinking, clever analysis, or arbitrary untestable assumptions can license unambiguous inference about causes of effects, even when the model is simple and the data are extensive (unless one is lucky enough to discover uniformity among units).\n\n“Wishful thinking” and “clever analysis,” I agree with, but arbitrary untestable assumptions can get you pretty far — But I agree with him in principle here. I think it’s practically impossible to take a recorded history and give a rigorous treatment to why it played out the way it did using statistical machinery, as far as I can tell. This is in large part due to the problem of fundamental causes: eventually we’ll get to a statement like “X happened because the Universe began” which is profoundly unsatisfying."
  },
  {
    "objectID": "2000_Dawid/2000_Dawid.html#a-decision-analytic-framework",
    "href": "2000_Dawid/2000_Dawid.html#a-decision-analytic-framework",
    "title": "4  Causal Inference Without Counterfactuals",
    "section": "A Decision-Analytic Framework",
    "text": "A Decision-Analytic Framework\nI find this a bit strange, but Dawid claims that “the counterfactual approach typically takes as the fundamental object of causal inference the  individual causal effect…”\nI can’t tell if it’s that I’m not very familiar with what the field of causal inference looked like pre-1980 or so, or if it’s just that this is a mischaracterization. Either way, what I’m familiar with is exclusively causal inference literature that takes as its main object of interest the average treatment effect or another population-level treatment effect (perhaps conditioned if thinking about effect-heterogeneity).\nNonetheless, Dawid mounts criticism of the counterfactual framework as involving “metaphysical” variables (variables we do not directly observe) and suggests a Bayesian decision-analytic alternative to the counterfactual formulation of causal inference instead.\nRather than investigating the properties of \\(Y_1 - Y_0\\) (the individual causal effect) (or even \\(\\mathbb E[Y_1] - \\mathbb E[Y_0]\\), the average treatment effect), instead Dawid suggests that what we should do is:\n\nRestrict our studies to perfectly homogeneous populations so as to banish any potential confounders;\nLook at the “physical array” of values representing the outcomes of treated and untreated units to develop a prediction model;\nAnd for any questions about whether or not treatment should be assigned in the future, we should use a Bayesian decision-theoretic model to infer the optimality choice based on the distributions of observed outcomes for treated vs. untreated.\n\nDawid does grant that models could be developed for nonhomogeneous populations, suggesting that “symmetry arguments” can be used to “justify the construction of certain random-effects-type models …”\nHe goes on to say, “As long as one’s models relate the responses of the new and the old units (under arbitrary treatment assignments), and so support the required predictive inferences, one can conduct whatever decision-analytic analysis appears most relevant to one’s purpose, eschewing counterfactuals entirely.”\nIt seems to me that one of the following two statements must be true, depending on how comfortable Dawid is with the line of thought that the decision-analytic framework could support nonhomogeneous populations:\n\nRestricting causal inference to only homogeneous populations would be incredibly restrictive and would render a huge number of problems for which data already exist in economics, sociology, health sciences, and education un-workable.\nIf we’re allowing ourselves to control for potential confounders in prediction models that are used for a Bayesian decision-analytic approach, I’m suspicious we’re treading awfully close to a modeling approach that, while in its description may sound different, is fundamentally doing something extremely similar to the usual counterfactual approach."
  },
  {
    "objectID": "2000_Dawid/2000_Dawid.html#philosophy-and-fatalism",
    "href": "2000_Dawid/2000_Dawid.html#philosophy-and-fatalism",
    "title": "4  Causal Inference Without Counterfactuals",
    "section": "Philosophy and “Fatalism”",
    "text": "Philosophy and “Fatalism”\n\nMany counterfactual analyses are based, explicitly or implicity, on an attitude that I term “fatalism.” This considers the various potential responses \\(Y_i(u)\\), when treatment \\(i\\) is applied to unit \\(u\\), as predetermined attributes of unit \\(u\\), waiting only to be uncovered by suitable experimentation.\n\nIt’s a little bit hard here to disentangle whether Dawid is talking about 1) whether the Universe is a deterministic or stochastic place, or 2) whether he’s saying that counterfactuals are themselves random or fixed variables.\nHowever, he goes on to say:\n\nFor example, it [the fatalistic worldview] leaves no scope for introducing realistic stochastic effects of external influences acting between times of application of treatment and of the response.\n\nSo it sounds a lot like he’s saying he thinks that much of the approach of counterfactual causal inference is rooted in an assumption that the counterfactual is itself not a random variable, which I just simply don’t agree with as that’s not a presentation or approach I’ve ever seen advocated for."
  },
  {
    "objectID": "2000_Dawid/2000_Dawid.html#have-we-constructed-a-strawman",
    "href": "2000_Dawid/2000_Dawid.html#have-we-constructed-a-strawman",
    "title": "4  Causal Inference Without Counterfactuals",
    "section": "Have we constructed a strawman?",
    "text": "Have we constructed a strawman?\nAt one point (section 9.1), Dawid says that the average causal effect (in his notation: \\(\\mathbb E_p\\{f(Y_t) - f(Y_c)\\}\\)) (I take in a population where exchangeability, positivity, and consistency hold) is just \\(\\mathbb E_P \\{f(Y_t)\\} - \\mathbb E_P \\{ f(Y_c) \\}\\) and this only depends on the marginal distributions.\n\nHence this particular use of counterfactual analysis, focusing on an infinite population ACE, is consistent with the decision-analytic approach and involves only terms subject to empirical scrutiny. It is fortunate that many of the superficially counterfactual analyses in the literature, from Rubin (1978) onward, have in fact confined attention to ACE and thus lead to acceptable conclusions.\n\nAt this point, I’m questioning what exactly Dawid is attacking given that he clearly says much of the causal inference literature is acceptable."
  },
  {
    "objectID": "2000_Dawid/2000_Dawid.html#conclusions",
    "href": "2000_Dawid/2000_Dawid.html#conclusions",
    "title": "4  Causal Inference Without Counterfactuals",
    "section": "“Conclusions”",
    "text": "“Conclusions”\n\nThere is no magical statistical route that can bypass the need to do real science to attain the clearest possible understanding of the operation of relevant (typically nondeterministic) causal mechanisms.\n\nThere’s a lot to unpack there. First, I think it’s a real bold move to assume that you can litigate what “real” science is and isn’t. Second, it’s news to me if we’ve settled the debate on whether the universe is deterministic or not, but insofar as its relevant to this discussion, it doesn’t really matter as long as long as the best models we have for sufficiently complex future outcomes are those of random data generation mechanisms."
  },
  {
    "objectID": "2000_Dawid/2000_Dawid.html#cox",
    "href": "2000_Dawid/2000_Dawid.html#cox",
    "title": "4  Causal Inference Without Counterfactuals",
    "section": "Cox",
    "text": "Cox\nOf all the responses, I thought the one that hit the nail on the head was David R. Cox’s:\n\nhas the philosophical coherence, if not thrown the baby out with the bathwater, at least left the baby seriously bruised in some vital organs?\n\nIn other words: is Dawid making perfect the enemy of good?\nI agree with Cox that “it is hard to disagree with Dawid’s distate for assumptions that can never be tested… Yet at a work-a-day level, the point is more that any assumptions should not be pressed too far beyond the limits to which they can be tested, and importantly, that assumptions can be tested indirectly via their consequences as well as directly.”\nI think Cox also raises an interesting philosophical question about causality, which is that is causal inference truly causal if it lacks explanation? As in, if a carefully randomized experiment (or even series of experiments) shows that T produces higher responses than C, but no understanding as to how is established, is it the case that causality has been established? “In one sense it has, and yet I believe that many working scientists would be uneasy using the term in such situations.”"
  },
  {
    "objectID": "2000_Dawid/2000_Dawid.html#casella-and-schwartz",
    "href": "2000_Dawid/2000_Dawid.html#casella-and-schwartz",
    "title": "4  Causal Inference Without Counterfactuals",
    "section": "Casella and Schwartz",
    "text": "Casella and Schwartz\n\nDawid insists that such choices, and inferences, must be based on strict principles that can be verified empirically. We believe that such a program is so overly rigid that, in the end, science is not served.\n\nOf particular note to me is the historical evidence that Casella and Schwartz bring to the table — already in 1748, philosopher David Hume was thinking about causal inference and making the distinction of token vs. type causation:\n\nIt appears, then, that this idea of a necessary connection among events arises from a number of similar instances which occur, of the constant conjunction of these events; nor can that idea ever be suggested by any one of these instances surveyed in all possible lights and positions.\n\nCasella and Schwartz also note that it feels like Dawid has substantially changed the inferential target of interest from the average causal effect to the decision-theoretically important quantity \\(u_0 | \\text{treatment} = t\\)."
  },
  {
    "objectID": "2000_Dawid/2000_Dawid.html#pearl",
    "href": "2000_Dawid/2000_Dawid.html#pearl",
    "title": "4  Causal Inference Without Counterfactuals",
    "section": "Pearl",
    "text": "Pearl"
  }
]